{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "39dcae59",
      "metadata": {
        "id": "39dcae59"
      },
      "source": [
        "# Waste Transfer Learning Assignment\n",
        "\n",
        "Full ready-to-run notebook for the Coursera peer-graded assignment: **Classify Waste Products Using Transfer Learning**.\n",
        "\n",
        "**How to use**:\n",
        "- Update the dataset paths (`train_dir`, `val_dir`, `test_dir`) to point to your data folders (each folder should contain class subfolders).\n",
        "- Run the cells in order (recommended in Google Colab or Jupyter).\n",
        "- The notebook prints and saves the outputs required by Coursera for screenshot submission.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64498ef1",
      "metadata": {
        "id": "64498ef1",
        "outputId": "3daebef7-d14c-49d0-f72c-bd198fe12a49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.19.0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/data/train'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1598321246.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0mtest_datagen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrescale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m train_generator = train_datagen.flow_from_directory(\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \u001b[0mkeep_aspect_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m     ):\n\u001b[0;32m-> 1138\u001b[0;31m         return DirectoryIterator(\n\u001b[0m\u001b[1;32m   1139\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/data/train'"
          ]
        }
      ],
      "source": [
        "# Imports and configuration\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# ---------------------------\n",
        "# User configuration - EDIT\n",
        "# ---------------------------\n",
        "# Point these to your dataset directory structure (train/val/test each with class subfolders)\n",
        "train_dir = '/content/data/train'    # <-- update\n",
        "val_dir   = '/content/data/val'      # <-- update\n",
        "test_dir  = '/content/data/test'     # <-- update\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS_EXTRACT = 8\n",
        "NUM_EPOCHS_FINETUNE = 6\n",
        "SEED = 123\n",
        "INDEX_TO_PLOT = 1  # as required by the assignment\n",
        "\n",
        "# ---------------------------\n",
        "# Task 1: Print TF version\n",
        "# ---------------------------\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "\n",
        "# ---------------------------\n",
        "# Reproducibility\n",
        "# ---------------------------\n",
        "tf.random.set_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "# ---------------------------\n",
        "# Data generators\n",
        "# ---------------------------\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# test_datagen - requested in tasks\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True,\n",
        "    seed=SEED\n",
        ")\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False,\n",
        "    seed=SEED\n",
        ")\n",
        "\n",
        "# ---------------------------\n",
        "# Task 2: create test_generator using test_datagen\n",
        "# ---------------------------\n",
        "# Important: shuffle=False so that predictions correspond to file order\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=1,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# For screenshot: show an example batch from test_generator\n",
        "imgs, labels = next(test_generator)\n",
        "print('Example test batch shape (images, labels):', imgs.shape, labels.shape)\n",
        "\n",
        "# ---------------------------\n",
        "# Task 3: Print the length of train_generator\n",
        "# ---------------------------\n",
        "print('Length of train_generator (number of batches):', len(train_generator))\n",
        "\n",
        "# ---------------------------\n",
        "# Build the model - Extract Features Model\n",
        "# ---------------------------\n",
        "num_classes = len(train_generator.class_indices)\n",
        "print('Number of classes:', num_classes)\n",
        "\n",
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "base_model.trainable = False  # Extract-features stage: freeze base\n",
        "\n",
        "inputs = keras.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
        "x = tf.keras.applications.mobilenet_v2.preprocess_input(inputs)\n",
        "x = base_model(x, training=False)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "extract_model = keras.Model(inputs, outputs, name='extract_features_model')\n",
        "\n",
        "# ---------------------------\n",
        "# Task 4: Print the model summary\n",
        "# ---------------------------\n",
        "print('\\\\n--- Extract Features Model Summary ---')\n",
        "extract_model.summary()\n",
        "\n",
        "# ---------------------------\n",
        "# Task 5: Compile the model\n",
        "# ---------------------------\n",
        "extract_model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "print('\\\\nModel compiled (extract features).')\n",
        "\n",
        "# ---------------------------\n",
        "# Train Extract-Features Model\n",
        "# ---------------------------\n",
        "history_extract = extract_model.fit(\n",
        "    train_generator,\n",
        "    epochs=NUM_EPOCHS_EXTRACT,\n",
        "    validation_data=validation_generator\n",
        ")\n",
        "\n",
        "# Save history plot for Task 6 (accuracy curves for extract-features model)\n",
        "plt.figure()\n",
        "plt.plot(history_extract.history['accuracy'], label='train_accuracy')\n",
        "plt.plot(history_extract.history['val_accuracy'], label='val_accuracy')\n",
        "plt.title('Extract-Features Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig('task6_extract_accuracy.png', bbox_inches='tight')\n",
        "print(\"Saved 'task6_extract_accuracy.png' (Task 6).\")\n",
        "\n",
        "# ---------------------------\n",
        "# Fine-tuning stage\n",
        "# ---------------------------\n",
        "base_model.trainable = True\n",
        "fine_tune_at = int(len(base_model.layers) * 0.8)  # unfreeze top 20%\n",
        "for i, layer in enumerate(base_model.layers):\n",
        "    layer.trainable = i >= fine_tune_at\n",
        "\n",
        "fine_tune_inputs = keras.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
        "x = tf.keras.applications.mobilenet_v2.preprocess_input(fine_tune_inputs)\n",
        "x = base_model(x, training=True)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "fine_tune_outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "fine_tune_model = keras.Model(fine_tune_inputs, fine_tune_outputs, name='fine_tune_model')\n",
        "\n",
        "fine_tune_model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print('\\\\n--- Fine-tune Model Summary ---')\n",
        "fine_tune_model.summary()\n",
        "\n",
        "history_finetune = fine_tune_model.fit(\n",
        "    train_generator,\n",
        "    epochs=NUM_EPOCHS_FINETUNE,\n",
        "    validation_data=validation_generator\n",
        ")\n",
        "\n",
        "# ---------------------------\n",
        "# Task 7 & 8: Save loss and accuracy plots for fine-tuned model\n",
        "# ---------------------------\n",
        "plt.figure()\n",
        "plt.plot(history_finetune.history['loss'], label='train_loss')\n",
        "plt.plot(history_finetune.history['val_loss'], label='val_loss')\n",
        "plt.title('Fine-tune Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig('task7_finetune_loss.png', bbox_inches='tight')\n",
        "print(\"Saved 'task7_finetune_loss.png' (Task 7).\")\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history_finetune.history['accuracy'], label='train_accuracy')\n",
        "plt.plot(history_finetune.history['val_accuracy'], label='val_accuracy')\n",
        "plt.title('Fine-tune Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig('task8_finetune_accuracy.png', bbox_inches='tight')\n",
        "print(\"Saved 'task8_finetune_accuracy.png' (Task 8).\")\n",
        "\n",
        "# ---------------------------\n",
        "# Save models\n",
        "# ---------------------------\n",
        "extract_model.save('extract_model.h5')\n",
        "fine_tune_model.save('fine_tune_model.h5')\n",
        "print('Saved extract_model.h5 and fine_tune_model.h5')\n",
        "\n",
        "# ---------------------------\n",
        "# Task 9: Plot a test image using Extract Features Model (index_to_plot = 1)\n",
        "# ---------------------------\n",
        "test_generator.reset()\n",
        "\n",
        "filenames = test_generator.filenames\n",
        "true_labels = test_generator.classes\n",
        "class_indices = test_generator.class_indices\n",
        "index_to_class = {v: k for k, v in class_indices.items()}\n",
        "\n",
        "print('Test filenames example:', filenames[:5])\n",
        "print('Index to class mapping:', index_to_class)\n",
        "\n",
        "extract_preds = extract_model.predict(test_generator, steps=len(test_generator), verbose=1)\n",
        "extract_pred_classes = np.argmax(extract_preds, axis=1)\n",
        "\n",
        "idx = INDEX_TO_PLOT\n",
        "img_path = os.path.join(test_dir, filenames[idx])\n",
        "img = keras.preprocessing.image.load_img(img_path, target_size=IMG_SIZE)\n",
        "img_arr = keras.preprocessing.image.img_to_array(img)/255.0\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(img_arr)\n",
        "plt.axis('off')\n",
        "pred_label = index_to_class[int(extract_pred_classes[idx])]\n",
        "true_label = index_to_class[int(true_labels[idx])]\n",
        "plt.title(f'Extract Model Prediction: {pred_label} | True: {true_label}')\n",
        "plt.savefig('task9_extract_test_image.png', bbox_inches='tight')\n",
        "print(\"Saved 'task9_extract_test_image.png' (Task 9).\")\n",
        "\n",
        "# ---------------------------\n",
        "# Task 10: Plot a test image using Fine-Tuned Model (index_to_plot = 1)\n",
        "# ---------------------------\n",
        "test_generator.reset()\n",
        "finetune_preds = fine_tune_model.predict(test_generator, steps=len(test_generator), verbose=1)\n",
        "finetune_pred_classes = np.argmax(finetune_preds, axis=1)\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(img_arr)\n",
        "plt.axis('off')\n",
        "pred_label_ft = index_to_class[int(finetune_pred_classes[idx])]\n",
        "plt.title(f'Fine-tuned Model Prediction: {pred_label_ft} | True: {true_label}')\n",
        "plt.savefig('task10_finetune_test_image.png', bbox_inches='tight')\n",
        "print(\"Saved 'task10_finetune_test_image.png' (Task 10).\")\n",
        "\n",
        "print('\\\\nAll required artifacts are saved as PNG files in the working directory:')\n",
        "print('- task6_extract_accuracy.png')\n",
        "print('- task7_finetune_loss.png')\n",
        "print('- task8_finetune_accuracy.png')\n",
        "print('- task9_extract_test_image.png')\n",
        "print('- task10_finetune_test_image.png')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lT7lz7BY_XEP"
      },
      "id": "lT7lz7BY_XEP",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}